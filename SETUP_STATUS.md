# Roku AI - Setup Status

**Date:** February 6, 2026  
**Status:** âœ… Ready for Daily Use

---

## âœ… Completed

### 1. **DeepSeek-R1 14B Downloaded**
- Model: `DeepSeek-R1-Distill-Qwen-14B-Q4_K_M.gguf`
- Size: 8.4GB (4-bit quantized)
- Location: `~/Roku/roku-ai/models/base/`
- **Upgrade from:** Llama 3.2 3B â†’ DeepSeek-R1 14B (better reasoning)

### 2. **GUI Interface Created**
- File: `interfaces/roku_gui.py`
- Features:
  - Clean chat interface with dark theme
  - Real-time LoRA adapter monitoring
  - Performance metrics (latency, query count)
  - Interaction logging for research
  - Auto-save conversations

### 3. **LoRA Adapters Trained**
- âœ… **personality.gguf** (46MB) - Conversational style
- âœ… **personal.gguf** (50MB) - Your facts & preferences

### 4. **Profile System**
- User profile: `data/profiles/Srimaan.json`
- Contains your background, work, schedule, preferences
- Used for context injection (no hallucination)

---

## ğŸš€ How to Launch

### **Option 1: Using Launcher Script**
```bash
cd ~/Roku/roku-ai
./launch_roku_gui.sh
```

### **Option 2: Direct Python**
```bash
cd ~/Roku/roku-ai
python interfaces/roku_gui.py
```

---

## ğŸ“Š What to Track (For Research)

The GUI automatically logs to `data/conversations/`:
1. **Adapter usage** - which LoRAs activate for each query
2. **Latency** - response time per query
3. **Failure modes** - where adapters struggle
4. **Usage patterns** - what you actually ask daily

**Use this data for:** Implementing Thousand Brains voting layer

---

## ğŸ¯ Next Steps

### **Week 1: Stress Test**
- [ ] Use Roku daily for all queries
- [ ] Log everything
- [ ] Identify limitations

### **Week 2: Analyze Data**
- [ ] Review conversation logs
- [ ] Find patterns where single adapters fail
- [ ] Identify need for voting mechanism

### **Week 3: Implement Voting Layer**
- [ ] Add column voting (Thousand Brains Theory)
- [ ] Test multi-adapter consensus
- [ ] Compare vs single adapter performance

### **Future:**
- [ ] Add more domain adapters (work, health, home)
- [ ] Vision model integration (Qwen-VL or similar)
- [ ] Overnight analysis pipeline
- [ ] Even G2 integration (when accepted)

---

## ğŸ§  Research Framework

### **Hypothesis:**
Multi-LoRA composition with Thousand Brains voting will outperform single large models for personalized tasks.

### **What You're Testing:**
1. **Composition > Scale** - 14B base + 50MB adapters vs 70B monolithic
2. **Specialization > Generalization** - Domain experts vs general knowledge
3. **Continuous Learning** - Nightly adapter updates vs static weights

### **Metrics to Track:**
- Response quality (your subjective rating)
- Adapter activation patterns
- Failure modes per domain
- Latency differences

---

## ğŸ› ï¸ Troubleshooting

### **If GUI doesn't launch:**
```bash
# Check dependencies
cd ~/Roku/roku-ai
pip install -r requirements.txt

# Test model loading
python test_deepseek_simple.py
```

### **If model is slow:**
- DeepSeek-R1 14B is ~4x larger than Llama 3.2 3B
- First inference will be slow (loading to RAM/VRAM)
- Subsequent queries should be faster
- Consider switching back to Llama 3.2 3B if too slow

### **To switch models:**
Edit `core/multi_lora.py` line 37:
```python
# DeepSeek-R1 14B (better reasoning, slower)
DEFAULT_MODEL_PATH = Path.home() / "Roku/roku-ai/models/base/DeepSeek-R1-Distill-Qwen-14B-Q4_K_M.gguf"

# OR Llama 3.2 3B (faster, less capable)
DEFAULT_MODEL_PATH = Path.home() / "Roku/roku-ai/models/base/Llama-3.2-3B-Instruct-Q4_K_M.gguf"
```

---

## ğŸ“ Project Structure

```
roku-ai/
â”œâ”€â”€ core/                   # Core AI functionality
â”‚   â”œâ”€â”€ multi_lora.py      # Multi-LoRA system âœ¨
â”‚   â”œâ”€â”€ personalized_roku.py
â”‚   â””â”€â”€ context_manager.py # Profile & context injection
â”œâ”€â”€ interfaces/
â”‚   â”œâ”€â”€ roku_gui.py        # Daily driver GUI âœ¨
â”‚   â””â”€â”€ cli.py
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ base/              # LLM models
â”‚   â”‚   â”œâ”€â”€ DeepSeek-R1-Distill-Qwen-14B-Q4_K_M.gguf âœ¨ (8.4GB)
â”‚   â”‚   â””â”€â”€ Llama-3.2-3B-Instruct-Q4_K_M.gguf (1.9GB)
â”‚   â””â”€â”€ adapters/          # LoRA adapters
â”‚       â”œâ”€â”€ personality.gguf âœ¨ (46MB)
â”‚       â””â”€â”€ personal.gguf âœ¨ (50MB)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ profiles/          # User profiles
â”‚   â”‚   â””â”€â”€ Srimaan.json âœ¨
â”‚   â””â”€â”€ conversations/     # Auto-saved logs
â””â”€â”€ training/              # Adapter training pipeline
```

---

## ğŸ’¡ Tips for Daily Use

1. **Ask varied questions** - test different domains
2. **Note failures** - when Roku doesn't know something
3. **Check the logs** - see which adapters activated
4. **Rate responses** - mental note of quality
5. **Save interesting conversations** - for training data

---

**Ready to start!** Launch the GUI and begin your Thousand Brains research! ğŸ§ 
